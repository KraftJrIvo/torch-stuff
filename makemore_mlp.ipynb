{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a085c791-939a-4508-9e0b-f6930a7f9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS_FILE = 'names.txt'\n",
    "words = open(WORDS_FILE, 'r', encoding=\"utf8\").read().splitlines()\n",
    "words = [w.lower() for w in words]\n",
    "words = [w for w in words if (len(w) > 0)]\n",
    "words[:10]\n",
    "letters = sorted(list(set(''.join(words))))\n",
    "chtoi = {ch:(i+1) for i,ch in enumerate(letters)}\n",
    "chtoi['.'] = 0\n",
    "itoch = {i:ch for ch,i in chtoi.items()}\n",
    "N = len(letters) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3851be3-6bf6-4cb7-a856-15fa56656d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "CTX_SZ = 4\n",
    "\n",
    "def make_dataset(words):\n",
    "    x, y = [], []\n",
    "    for w in words:        \n",
    "        ctx = [0] * CTX_SZ\n",
    "        for ch in w + '.':\n",
    "            idx = chtoi[ch]\n",
    "            x.append(ctx)\n",
    "            y.append(idx)\n",
    "            ctx = ctx[1:] + [idx]\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y)\n",
    "    return x, y\n",
    "\n",
    "import random\n",
    "random.seed(244)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "x_trn, y_trn = make_dataset(words[:n1])\n",
    "x_dev, y_dev = make_dataset(words[n1:n2])\n",
    "x_tst, y_tst = make_dataset(words[n2:])\n",
    "\n",
    "N_SAMPLES_TRN = x_trn.shape[0]\n",
    "N_SAMPLES_DEV = x_dev.shape[0]\n",
    "N_SAMPLES_TST = x_tst.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2b09793-0f60-4da9-8a7d-81025a25c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "HID_L_SZ = 200\n",
    "EMB_DIM = 3\n",
    "\n",
    "C = torch.randn((N, EMB_DIM))\n",
    "W1 = torch.randn((CTX_SZ * EMB_DIM, HID_L_SZ)) * 0.1\n",
    "b1 = torch.randn(HID_L_SZ)                     * 0.01\n",
    "W2 = torch.randn((HID_L_SZ, N))                * 0.01\n",
    "b2 = torch.randn(N)                            * 0\n",
    "params = [C, W1, b1, W2, b2]\n",
    "for p in params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d16a9f-5c3d-4c65-9ce3-284f0b221271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2934956550598145\n"
     ]
    }
   ],
   "source": [
    "ITS = 400000\n",
    "BATCH_SZ = 128\n",
    "\n",
    "lre = torch.linspace(-3, 0, ITS)\n",
    "lrs = 10**lre\n",
    "LR = 0.1\n",
    "losses = []\n",
    "\n",
    "def eval_loss(x, y, batch):\n",
    "    if batch is not None:\n",
    "        emb = C[x[batch]].view(-1, CTX_SZ * EMB_DIM)\n",
    "    else:\n",
    "        emb = C[x].view(-1, CTX_SZ * EMB_DIM)\n",
    "    h = torch.tanh(emb @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    if batch is not None:\n",
    "        loss = F.cross_entropy(logits, y[batch])\n",
    "    else:\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "    return loss\n",
    "\n",
    "for i in range(ITS):\n",
    "    bix = torch.randint(0, N_SAMPLES_TRN, (BATCH_SZ,))\n",
    "    loss = eval_loss(x_trn, y_trn, bix)\n",
    "    for p in params:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    lr = (LR/10) if (i > ITS / 2) else LR\n",
    "    for p in params:\n",
    "        p.data -= LR * p.grad\n",
    "    if i % 40000 == 0:\n",
    "        print(loss.item())\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03816295-fe51-4f5d-ab9f-7d024bc3ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(8,8))\n",
    "#plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
    "#for i in range(C.shape[0]):\n",
    "#    plt.text(C[i,0].item(), C[i,1].item(), itoch[i], ha='center', va='center', color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f02482f1-5bd4-4e71-9192-f20132fa59f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3570163249969482\n"
     ]
    }
   ],
   "source": [
    "print(eval_loss(x_dev, y_dev, None).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d55e3684-0e19-40f8-96b2-aaea3f76af1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 27])\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "idx = 0\n",
    "for k in range(20):\n",
    "    word = ''\n",
    "    ctx = [0] * CTX_SZ\n",
    "    while True:\n",
    "        emb = C[torch.tensor(ctx)].view(-1, CTX_SZ * EMB_DIM)\n",
    "        h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        idx = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "        ctx = ctx[1:] + [idx]\n",
    "        if idx == 0:\n",
    "            print(word)\n",
    "            break\n",
    "        word += itoch[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d753796-21ad-4313-a8e3-89525e52986d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
